{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31aed033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forcing CPU-only mode. TensorFlow devices visible: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "Using batch size = 32\n",
      "Loading training data from: im1\\train\n",
      "Loading validation data from: im1\\val\n",
      "Found 2929 files belonging to 5 classes.\n",
      "Found 733 files belonging to 5 classes.\n",
      "Detected classes: ['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']\n",
      "Training image counts per class (filesystem): {'Mild': 296, 'Moderate': 799, 'No_DR': 1444, 'Proliferate_DR': 236, 'Severe': 154}\n",
      "Computed class weights: {0: 1.979054054054054, 1: 0.7331664580725907, 2: 0.4056786703601108, 3: 2.4822033898305085, 4: 3.803896103896104}\n",
      "Detected strong class imbalance (ratio=9.38) — using focal loss\n",
      "Datasets cached in memory (if there is available RAM)\n",
      "Applied MixUp augmentation to training dataset (TF-native)\n",
      "Final hyperparameters to use:\n",
      " lr= 0.0001  dropout= 0.5  dense= 512  use_focal= True  weight_decay= 0.0001  fine_tune_at= 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TrueDivide</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">299</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">21,802,784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_190         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_191         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sequential_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ true_divide_1 (\u001b[38;5;33mTrueDivide\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ subtract_1 (\u001b[38;5;33mSubtract\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m299\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ inception_v3 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m21,802,784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_190         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_191         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │         \u001b[38;5;34m2,565\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,434,469</span> (93.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,434,469\u001b[0m (93.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,628,613</span> (10.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,628,613\u001b[0m (10.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,805,856</span> (83.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m21,805,856\u001b[0m (83.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting initial training (frozen backbone) ---\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740ms/step - accuracy: 0.2278 - loss: 0.5741"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 933ms/step - accuracy: 0.2663 - loss: 0.5551 - val_accuracy: 0.5689 - val_loss: 0.1954\n",
      "Epoch 2/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 935ms/step - accuracy: 0.3636 - loss: 0.4891 - val_accuracy: 0.4188 - val_loss: 0.1892\n",
      "Epoch 3/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745ms/step - accuracy: 0.4028 - loss: 0.4356"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 924ms/step - accuracy: 0.4135 - loss: 0.4261 - val_accuracy: 0.5798 - val_loss: 0.1602\n",
      "Epoch 4/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.3932 - loss: 0.4474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 897ms/step - accuracy: 0.4029 - loss: 0.4401 - val_accuracy: 0.6166 - val_loss: 0.1517\n",
      "Epoch 5/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748ms/step - accuracy: 0.4251 - loss: 0.4186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 924ms/step - accuracy: 0.4285 - loss: 0.4144 - val_accuracy: 0.6303 - val_loss: 0.1377\n",
      "Epoch 6/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 894ms/step - accuracy: 0.4234 - loss: 0.4100 - val_accuracy: 0.5839 - val_loss: 0.1675\n",
      "Epoch 7/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751ms/step - accuracy: 0.4467 - loss: 0.3872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 927ms/step - accuracy: 0.4466 - loss: 0.3885 - val_accuracy: 0.6508 - val_loss: 0.1291\n",
      "Epoch 8/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 917ms/step - accuracy: 0.4554 - loss: 0.3789 - val_accuracy: 0.6235 - val_loss: 0.1439\n",
      "Epoch 9/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 919ms/step - accuracy: 0.4513 - loss: 0.3791 - val_accuracy: 0.6126 - val_loss: 0.1496\n",
      "Epoch 10/10\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 921ms/step - accuracy: 0.4585 - loss: 0.3941 - val_accuracy: 0.6180 - val_loss: 0.1508\n",
      "\n",
      "--- Fine-tuning: unfreezing top layers of the base model ---\n",
      "\n",
      "Epoch 1/20\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874ms/step - accuracy: 0.3704 - loss: 0.4379"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 555\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    553\u001b[0m         callbacks_ft \u001b[38;5;241m=\u001b[39m callbacks_initial\n\u001b[1;32m--> 555\u001b[0m     history2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfine_tune_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_ft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    563\u001b[0m     history2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:401\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_epoch_iterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[0;32m    392\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m    393\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    400\u001b[0m     )\n\u001b[1;32m--> 401\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    411\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    413\u001b[0m }\n\u001b[0;32m    414\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:489\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    488\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(begin_step)\n\u001b[1;32m--> 489\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_end(end_step, logs)\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_evaluating:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CPU-only version of:\n",
    "Quantum Transfer Learning using InceptionV3 (feature extractor) + optional PennyLane quantum layer.\n",
    "\n",
    "This script forces TensorFlow to use CPU only (no GPUs), disables mixed precision, and preserves\n",
    "the remainder of your pipeline (dataset loading, MixUp, model, optional hyperparameter search, eval).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "# -------------------- FORCE CPU --------------------\n",
    "# Must set before importing tensorflow to ensure no GPU devices are used.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   # Force TF to ignore GPUs\n",
    "# Optionally set TF_CPP_MIN_LOG_LEVEL to reduce TF logging (0 = all, 1 = filter INFO, 2 = WARN, 3 = ERROR)\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# --------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Extra safety: if GPUs are still visible, hide them explicitly (no-op on CPU-only)\n",
    "try:\n",
    "    physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "    if physical_gpus:\n",
    "        try:\n",
    "            tf.config.set_visible_devices([], 'GPU')\n",
    "        except Exception:\n",
    "            # Some TF versions may raise; continue anyway\n",
    "            pass\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Optional packages\n",
    "try:\n",
    "    import optuna\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except Exception:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import keras_tuner as kt\n",
    "    KERASTUNER_AVAILABLE = True\n",
    "except Exception:\n",
    "    KERASTUNER_AVAILABLE = False\n",
    "\n",
    "# PennyLane for quantum layers (optional)\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    PENNYLANE_AVAILABLE = True\n",
    "except Exception:\n",
    "    PENNYLANE_AVAILABLE = False\n",
    "\n",
    "# matplotlib is optional. If missing, we'll fall back to saving numeric output.\n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    PLOTTING_AVAILABLE = True\n",
    "except Exception:\n",
    "    PLOTTING_AVAILABLE = False\n",
    "    plt = None\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "# --------------------------- User settings ---------------------------\n",
    "DATA_DIR = \"im1\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "IMG_SIZE = (299, 299)\n",
    "BATCH_SIZE = 32  # CPU-friendly default\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SEED = 123\n",
    "NUM_EPOCHS = 30\n",
    "INITIAL_EPOCHS = 10              # frozen-backbone training\n",
    "FINE_TUNE_EPOCHS = 20            # fine-tuning epochs\n",
    "FINE_TUNE_AT = 50                 # layers from the end of base_model to unfreeze\n",
    "DEFAULT_N_QUBITS = 4\n",
    "DEFAULT_Q_LAYERS = 2\n",
    "USE_QUANTUM = False               # keep False by default; enable only for experiments\n",
    "CACHE_DATASETS = True\n",
    "MIXUP_ALPHA = 0.15                # MixUp intensity (0 disables MixUp)\n",
    "LABEL_SMOOTHING = 0.08            # label smoothing for categorical crossentropy\n",
    "WEIGHT_DECAY = 1e-4               # AdamW weight decay\n",
    "DENSE_AFTER_Q = 512               # larger head\n",
    "DROPOUT_RATE = 0.5                # stronger dropout\n",
    "EARLYSTOP_PATIENCE = 10\n",
    "EXIT_AFTER_TRAIN = False         # run evaluation to generate confusion matrix\n",
    "\n",
    "# Hyperparameter search settings\n",
    "RUN_HP_SEARCH = False\n",
    "HP_TRIALS = 12\n",
    "HP_EPOCHS = 6\n",
    "HP_USE_OPTUNA = True\n",
    "\n",
    "# --------------------------- CPU / Strategy info ---------------------------\n",
    "# Use default strategy on CPU. We still call get_strategy() for compatibility.\n",
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Forcing CPU-only mode. TensorFlow devices visible:\", tf.config.get_visible_devices())\n",
    "print(f\"Using batch size = {BATCH_SIZE}\")\n",
    "# Note: mixed precision is intentionally NOT enabled for CPU training.\n",
    "\n",
    "# --------------------------- Utilities ---------------------------\n",
    "\n",
    "def compute_class_counts(train_dir):\n",
    "    classes = []\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    if not os.path.isdir(train_dir):\n",
    "        return classes, counts, total\n",
    "    for d in sorted(os.listdir(train_dir)):\n",
    "        cls_path = os.path.join(train_dir, d)\n",
    "        if os.path.isdir(cls_path):\n",
    "            cnt = len([f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))])\n",
    "            classes.append(d)\n",
    "            counts[d] = cnt\n",
    "            total += cnt\n",
    "    return classes, counts, total\n",
    "\n",
    "\n",
    "def compute_class_weight_from_counts(counts):\n",
    "    classes = sorted(counts.keys())\n",
    "    total = sum(counts.values())\n",
    "    num_classes = len(classes) if len(classes) > 0 else 1\n",
    "    class_weight = {}\n",
    "    for i, cls in enumerate(classes):\n",
    "        cls_count = counts[cls]\n",
    "        if cls_count == 0:\n",
    "            class_weight[i] = 1.0\n",
    "        else:\n",
    "            class_weight[i] = total / (num_classes * cls_count)\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "# TF-native MixUp (batch-wise)\n",
    "@tf.function\n",
    "def mixup_batch(images, labels, alpha=MIXUP_ALPHA):\n",
    "    if alpha <= 0.0:\n",
    "        return images, labels\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    lam = tf.random.uniform([], 0.0, 1.0)\n",
    "    lam = tf.maximum(lam, 1.0 - lam)\n",
    "    lam = tf.cast(lam, images.dtype)\n",
    "    idx = tf.random.shuffle(tf.range(batch_size))\n",
    "    mixed_images = lam * images + (1.0 - lam) * tf.gather(images, idx)\n",
    "    mixed_labels = lam * labels + (1.0 - lam) * tf.gather(labels, idx)\n",
    "    return mixed_images, mixed_labels\n",
    "\n",
    "\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        eps = 1e-7\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Learning rate schedule: linear warmup + cosine decay\n",
    "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, base_lr: float, total_steps: int, warmup_steps: int = 0, min_lr: float = 0.0, name: str = None):\n",
    "        super().__init__()\n",
    "        self.base_lr = float(base_lr)\n",
    "        self.total_steps = int(max(1, total_steps))\n",
    "        self.warmup_steps = int(max(0, warmup_steps))\n",
    "        self.min_lr = float(min_lr)\n",
    "        self.name = name or \"WarmUpCosine\"\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        total = tf.cast(self.total_steps, tf.float32)\n",
    "        warm = tf.cast(self.warmup_steps, tf.float32)\n",
    "        base = tf.constant(self.base_lr, tf.float32)\n",
    "        min_lr = tf.constant(self.min_lr, tf.float32)\n",
    "\n",
    "        def lr_warmup():\n",
    "            # Linear warmup from min_lr to base over warmup steps\n",
    "            slope = (base - min_lr) / tf.maximum(1.0, warm)\n",
    "            return min_lr + slope * step\n",
    "\n",
    "        def lr_cosine():\n",
    "            # Cosine decay from base to min_lr over (total - warmup) steps\n",
    "            progress = (step - warm) / tf.maximum(1.0, (total - warm))\n",
    "            cosine_decay = 0.5 * (1.0 + tf.cos(tf.constant(math.pi) * tf.clip_by_value(progress, 0.0, 1.0)))\n",
    "            return min_lr + (base - min_lr) * cosine_decay\n",
    "\n",
    "        return tf.cond(step < warm, lr_warmup, lr_cosine)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"base_lr\": self.base_lr,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"min_lr\": self.min_lr,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "\n",
    "# --------------------------- Load datasets ---------------------------\n",
    "print(f\"Loading training data from: {TRAIN_DIR}\")\n",
    "print(f\"Loading validation data from: {VAL_DIR}\")\n",
    "\n",
    "if not os.path.isdir(TRAIN_DIR) or not os.path.isdir(VAL_DIR):\n",
    "    print('Error: Train or Val directory not found. Please ensure the `im1/train` and `im1/val` directories exist and contain class subfolders.')\n",
    "    sys.exit(1)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(\"Detected classes:\", class_names)\n",
    "\n",
    "# compute counts & class weights\n",
    "classes_from_fs, counts, total = compute_class_counts(TRAIN_DIR)\n",
    "print('Training image counts per class (filesystem):', counts)\n",
    "class_weight = compute_class_weight_from_counts(counts)\n",
    "print('Computed class weights:', class_weight)\n",
    "\n",
    "imbalance_ratio = 1.0\n",
    "if counts:\n",
    "    min_count = min([v for v in counts.values() if v > 0])\n",
    "    if min_count > 0:\n",
    "        imbalance_ratio = max(counts.values()) / min_count\n",
    "use_focal = imbalance_ratio > 2.0\n",
    "if use_focal:\n",
    "    print(f\"Detected strong class imbalance (ratio={imbalance_ratio:.2f}) — using focal loss\")\n",
    "\n",
    "# Cache + prefetch\n",
    "if CACHE_DATASETS:\n",
    "    try:\n",
    "        train_ds = train_ds.cache()\n",
    "        val_ds = val_ds.cache()\n",
    "        print('Datasets cached in memory (if there is available RAM)')\n",
    "    except Exception as e:\n",
    "        print('Could not cache datasets:', e)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y), num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "if MIXUP_ALPHA > 0.0:\n",
    "    try:\n",
    "        train_ds = train_ds.map(lambda x, y: mixup_batch(x, y, MIXUP_ALPHA), num_parallel_calls=AUTOTUNE)\n",
    "        print('Applied MixUp augmentation to training dataset (TF-native)')\n",
    "    except Exception as e:\n",
    "        print('Could not apply MixUp via TF map — continuing without MixUp:', e)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.12),\n",
    "    layers.RandomZoom(0.12),\n",
    "    layers.RandomContrast(0.12),\n",
    "])\n",
    "\n",
    "# --------------------------- Quantum components (optional) ---------------------------\n",
    "if USE_QUANTUM and not PENNYLANE_AVAILABLE:\n",
    "    print(\"PennyLane not installed — quantum layer will be disabled automatically.\")\n",
    "    USE_QUANTUM = False\n",
    "\n",
    "# --------------------------- Model builder ---------------------------\n",
    "\n",
    "def build_feature_extractor():\n",
    "    base_model = tf.keras.applications.InceptionV3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    return base_model\n",
    "\n",
    "\n",
    "def build_model(base_model, n_qubits=DEFAULT_N_QUBITS, q_layers=DEFAULT_Q_LAYERS, lr=1e-4, dense_after_q=DENSE_AFTER_Q, use_quantum=USE_QUANTUM, dropout_rate=DROPOUT_RATE, label_smoothing=LABEL_SMOOTHING, use_focal_loss=False):\n",
    "    base_model.trainable = False\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = tf.keras.applications.inception_v3.preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    if use_quantum and PENNYLANE_AVAILABLE:\n",
    "        x = layers.Dense(n_qubits, activation='tanh', name='proj_to_qubits')(x)\n",
    "        # quantum head omitted here for clarity\n",
    "        x = layers.Dense(dense_after_q, activation='relu')(x)\n",
    "    else:\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Dense(dense_after_q, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax', dtype='float32', name='predictions')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    def make_optimizer(opt_name, lr, weight_decay=WEIGHT_DECAY):\n",
    "        try:\n",
    "            if opt_name == 'adamw':\n",
    "                Opt = tf.keras.optimizers.experimental.AdamW\n",
    "                return Opt(learning_rate=lr, weight_decay=weight_decay)\n",
    "            elif opt_name == 'adam':\n",
    "                return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            elif opt_name == 'sgd':\n",
    "                return tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "            else:\n",
    "                return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        except Exception:\n",
    "            return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    optimizer = make_optimizer('adamw', lr)\n",
    "\n",
    "    if use_focal_loss:\n",
    "        loss_fn = categorical_focal_loss()\n",
    "    else:\n",
    "        loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --------------------------- Hyperparameter search (optional) ---------------------------\n",
    "# (unchanged; will run on CPU if enabled)\n",
    "\n",
    "def run_optuna_search(train_ds, val_ds, base_model, class_weight, trials=12, epochs_per_trial=6):\n",
    "    if not OPTUNA_AVAILABLE:\n",
    "        print('Optuna not available — skipping Optuna search')\n",
    "        return None\n",
    "\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            opt_name = trial.suggest_categorical('optimizer', ['adamw', 'adam', 'sgd'])\n",
    "            lr = trial.suggest_loguniform('lr', 1e-6, 1e-3)\n",
    "            weight_decay = trial.suggest_loguniform('weight_decay', 1e-7, 1e-3)\n",
    "            dropout = trial.suggest_float('dropout', 0.2, 0.6)\n",
    "            dense_head = trial.suggest_categorical('dense_head', [256, 512, 768])\n",
    "            mixup_alpha = trial.suggest_float('mixup_alpha', 0.0, 0.25)\n",
    "            label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.12)\n",
    "            fine_tune_at = trial.suggest_int('fine_tune_at', 20, 80)\n",
    "            use_focal = trial.suggest_categorical('use_focal', [False, True])\n",
    "\n",
    "            with strategy.scope():\n",
    "                model = build_model(base_model, lr=lr, dense_after_q=dense_head, dropout_rate=dropout, label_smoothing=label_smoothing, use_focal_loss=use_focal)\n",
    "\n",
    "            cb = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "\n",
    "            ds_train_for_trial = train_ds\n",
    "            if mixup_alpha > 0:\n",
    "                try:\n",
    "                    ds_train_for_trial = ds_train_for_trial.map(lambda x, y: mixup_batch(x, y, mixup_alpha), num_parallel_calls=AUTOTUNE)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            history = model.fit(ds_train_for_trial, validation_data=val_ds, epochs=epochs_per_trial, callbacks=cb, class_weight=class_weight, verbose=0)\n",
    "            val_acc = history.history.get('val_accuracy', [0])[-1]\n",
    "            tf.keras.backend.clear_session()\n",
    "            return val_acc\n",
    "        except Exception as e:\n",
    "            print('Trial failed with exception:', e)\n",
    "            traceback.print_exc()\n",
    "            tf.keras.backend.clear_session()\n",
    "            return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "    print('Optuna study best params:', study.best_params)\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "def run_keras_tuner_search(train_ds, val_ds, base_model, class_weight, max_trials=8, epochs_per_trial=6):\n",
    "    if not KERASTUNER_AVAILABLE:\n",
    "        print('Keras Tuner not available — skipping tuner search')\n",
    "        return None\n",
    "\n",
    "    def model_builder(hp):\n",
    "        lr = hp.Float('lr', 1e-6, 1e-3, sampling='log', default=1e-4)\n",
    "        dropout = hp.Float('dropout', 0.2, 0.6, step=0.1, default=0.4)\n",
    "        dense_head = hp.Choice('dense_head', [256, 512, 768], default=512)\n",
    "        use_focal = hp.Boolean('use_focal', default=False)\n",
    "        model = build_model(base_model, lr=lr, dense_after_q=dense_head, dropout_rate=dropout, use_focal_loss=use_focal)\n",
    "        return model\n",
    "\n",
    "    tuner = kt.BayesianOptimization(model_builder, objective='val_accuracy', max_trials=max_trials, directory='kt_dir', project_name='quantum_inception_opt')\n",
    "    tuner.search(train_ds, validation_data=val_ds, epochs=epochs_per_trial, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)], class_weight=class_weight)\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print('Keras Tuner best hyperparameters:', best_hp.values)\n",
    "    return best_hp.values\n",
    "\n",
    "# --------------------------- Build, train, fine-tune (main) ---------------------------\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model = build_feature_extractor()\n",
    "\n",
    "best_hp = None\n",
    "if RUN_HP_SEARCH:\n",
    "    print('Starting hyperparameter search...')\n",
    "    if OPTUNA_AVAILABLE and HP_USE_OPTUNA:\n",
    "        try:\n",
    "            best_hp = run_optuna_search(train_ds, val_ds, base_model, class_weight, trials=HP_TRIALS, epochs_per_trial=HP_EPOCHS)\n",
    "        except Exception as e:\n",
    "            print('Optuna search failed:', e)\n",
    "            best_hp = None\n",
    "    if best_hp is None and KERASTUNER_AVAILABLE:\n",
    "        try:\n",
    "            best_hp = run_keras_tuner_search(train_ds, val_ds, base_model, class_weight, max_trials=HP_TRIALS, epochs_per_trial=HP_EPOCHS)\n",
    "        except Exception as e:\n",
    "            print('Keras Tuner search failed:', e)\n",
    "            best_hp = None\n",
    "    print('Hyperparameter search complete. best_hp =', best_hp)\n",
    "\n",
    "if isinstance(best_hp, dict):\n",
    "    chosen_lr = best_hp.get('lr', 1e-4)\n",
    "    chosen_dropout = best_hp.get('dropout', DROPOUT_RATE)\n",
    "    chosen_dense = best_hp.get('dense_head', DENSE_AFTER_Q)\n",
    "    chosen_use_focal = best_hp.get('use_focal', use_focal)\n",
    "    chosen_weight_decay = best_hp.get('weight_decay', WEIGHT_DECAY)\n",
    "    chosen_fine_tune_at = best_hp.get('fine_tune_at', FINE_TUNE_AT)\n",
    "else:\n",
    "    chosen_lr = 1e-4\n",
    "    chosen_dropout = DROPOUT_RATE\n",
    "    chosen_dense = DENSE_AFTER_Q\n",
    "    chosen_use_focal = use_focal\n",
    "    chosen_weight_decay = WEIGHT_DECAY\n",
    "    chosen_fine_tune_at = FINE_TUNE_AT\n",
    "\n",
    "print('Final hyperparameters to use:')\n",
    "print(' lr=', chosen_lr, ' dropout=', chosen_dropout, ' dense=', chosen_dense, ' use_focal=', chosen_use_focal, ' weight_decay=', chosen_weight_decay, ' fine_tune_at=', chosen_fine_tune_at)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model(base_model, lr=chosen_lr, dense_after_q=chosen_dense, dropout_rate=chosen_dropout, label_smoothing=LABEL_SMOOTHING, use_focal_loss=chosen_use_focal)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_filepath = 'best_quantum_inception_cpu.h5'\n",
    "callbacks_initial = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "steps_per_epoch = math.ceil(total / BATCH_SIZE) if total > 0 else None\n",
    "\n",
    "# Re-compile model with warmup+cosine schedule for initial training when step info is available\n",
    "with strategy.scope():\n",
    "    if steps_per_epoch:\n",
    "        init_total_steps = INITIAL_EPOCHS * steps_per_epoch\n",
    "        init_warmup_steps = max(1, int(0.1 * init_total_steps))\n",
    "        init_lr_schedule = WarmUpCosine(\n",
    "            base_lr=chosen_lr,\n",
    "            total_steps=init_total_steps,\n",
    "            warmup_steps=init_warmup_steps,\n",
    "            min_lr=max(1e-7, chosen_lr * 0.1),\n",
    "        )\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            init_optimizer = Opt(learning_rate=init_lr_schedule, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            init_optimizer = tf.keras.optimizers.Adam(learning_rate=init_lr_schedule)\n",
    "    else:\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            init_optimizer = Opt(learning_rate=chosen_lr, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            init_optimizer = tf.keras.optimizers.Adam(learning_rate=chosen_lr)\n",
    "    model.compile(optimizer=init_optimizer, loss=model.loss, metrics=['accuracy'])\n",
    "\n",
    "# Choose callbacks for initial training depending on whether a schedule is used\n",
    "if steps_per_epoch:\n",
    "    callbacks_init_actual = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n",
    "    ]\n",
    "else:\n",
    "    callbacks_init_actual = callbacks_initial\n",
    "\n",
    "print(\"\\n--- Starting initial training (frozen backbone) ---\\n\")\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    callbacks=callbacks_init_actual,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "# Fine-tune: unfreeze last chosen_fine_tune_at layers of base_model\n",
    "print(\"\\n--- Fine-tuning: unfreezing top layers of the base model ---\\n\")\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-chosen_fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-chosen_fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "fine_tune_epochs = FINE_TUNE_EPOCHS\n",
    "if steps_per_epoch is None:\n",
    "    decay_steps = None\n",
    "else:\n",
    "    decay_steps = fine_tune_epochs * steps_per_epoch\n",
    "\n",
    "with strategy.scope():\n",
    "    ft_lr = chosen_lr * 0.05\n",
    "    if decay_steps:\n",
    "        # Use the same WarmUpCosine with short warmup for fine-tuning\n",
    "        ft_warmup_steps = max(1, int(0.1 * decay_steps))\n",
    "        lr_schedule = WarmUpCosine(\n",
    "            base_lr=ft_lr,\n",
    "            total_steps=decay_steps,\n",
    "            warmup_steps=ft_warmup_steps,\n",
    "            min_lr=max(1e-7, ft_lr * 0.2),\n",
    "        )\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            optimizer = Opt(learning_rate=lr_schedule, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    else:\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            optimizer = Opt(learning_rate=ft_lr, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=ft_lr)\n",
    "    model.compile(optimizer=optimizer, loss=model.loss, metrics=['accuracy'])\n",
    "\n",
    "# Choose callbacks for fine-tuning depending on whether a schedule is used\n",
    "if fine_tune_epochs > 0:\n",
    "    if decay_steps:\n",
    "        callbacks_ft = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLYSTOP_PATIENCE, restore_best_weights=True)\n",
    "        ]\n",
    "    else:\n",
    "        callbacks_ft = callbacks_initial\n",
    "\n",
    "    history2 = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=fine_tune_epochs,\n",
    "        callbacks=callbacks_ft,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "else:\n",
    "    history2 = None\n",
    "\n",
    "# Save final model\n",
    "model.save('quantum_inception_trained_finetuned_cpu.h5')\n",
    "print('Saved trained & fine-tuned model to quantum_inception_trained_finetuned_cpu.h5')\n",
    "\n",
    "if EXIT_AFTER_TRAIN:\n",
    "    sys.exit(0)\n",
    "\n",
    "# --------------------------- Consolidate history ---------------------------\n",
    "\n",
    "def merge_history(h1, h2):\n",
    "    if h2 is None:\n",
    "        return h1\n",
    "    merged = {}\n",
    "    for k in h1.history.keys():\n",
    "        merged[k] = h1.history[k] + h2.history.get(k, [])\n",
    "    return type('H', (), {'history': merged})\n",
    "\n",
    "history = merge_history(history1, history2)\n",
    "\n",
    "# --------------------------- Plot training curves ---------------------------\n",
    "\n",
    "def save_metrics_json(history, out_prefix='train'):\n",
    "    metrics = history.history\n",
    "    out_file = f\"{out_prefix}_metrics.json\"\n",
    "    try:\n",
    "        with open(out_file, 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        print(f\"Saved numeric training metrics to {out_file}\")\n",
    "    except Exception as e:\n",
    "        print('Could not save JSON metrics:', e)\n",
    "\n",
    "\n",
    "def plot_training(history, out_prefix='train'):\n",
    "    if not PLOTTING_AVAILABLE:\n",
    "        print('matplotlib not available — saving numeric metrics instead of plots')\n",
    "        save_metrics_json(history, out_prefix=out_prefix)\n",
    "        return\n",
    "\n",
    "    acc = history.history.get('accuracy', [])\n",
    "    val_acc = history.history.get('val_accuracy', [])\n",
    "    loss = history.history.get('loss', [])\n",
    "    val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    acc_png = f\"{out_prefix}_accuracy.png\"\n",
    "    plt.savefig(acc_png)\n",
    "    print(f\"Saved accuracy plot to {acc_png}\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    loss_png = f\"{out_prefix}_loss.png\"\n",
    "    plt.savefig(loss_png)\n",
    "    print(f\"Saved loss plot to {loss_png}\")\n",
    "    plt.close()\n",
    "\n",
    "plot_training(history)\n",
    "\n",
    "# --------------------------- Evaluation ---------------------------\n",
    "\n",
    "def create_normal_confusion_matrix(cm, class_names, save_path='confusion_matrix.png'):\n",
    "    \"\"\"\n",
    "    Create a normal, clean confusion matrix with standard matplotlib styling\n",
    "    \"\"\"\n",
    "    if not PLOTTING_AVAILABLE:\n",
    "        return\n",
    "    \n",
    "    # Create figure with standard size\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Use standard colormap (Blues)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues', aspect='auto')\n",
    "    \n",
    "    # Add simple title\n",
    "    ax.set_title('Confusion Matrix - Diabetic Retinopathy Classification', \n",
    "                 fontsize=14, fontweight='normal', pad=20)\n",
    "    \n",
    "    # Add standard colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Number of Predictions', fontsize=10)\n",
    "    \n",
    "    # Set tick marks\n",
    "    tick_marks = np.arange(NUM_CLASSES)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n",
    "    ax.set_yticklabels(class_names, fontsize=10)\n",
    "    \n",
    "    # Add simple grid\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # Add text annotations with simple styling\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        value = cm[i, j]\n",
    "        \n",
    "        # Simple text color based on cell value\n",
    "        if value > thresh:\n",
    "            text_color = \"white\"\n",
    "        else:\n",
    "            text_color = \"black\"\n",
    "        \n",
    "        # Add the count with simple styling\n",
    "        ax.text(j, i, f'{value:d}',\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                color=text_color,\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Standard axis labels\n",
    "    ax.set_ylabel('True Label', fontsize=12)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "    \n",
    "    # Standard background\n",
    "    ax.set_facecolor('white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # Standard spines\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save with standard quality\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved normal confusion matrix to {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# --------------------------- Evaluation ---------------------------\n",
    "\n",
    "y_true_list = []\n",
    "y_prob_list = []\n",
    "\n",
    "for batch_images, batch_labels in val_ds:\n",
    "    y_true_list.append(batch_labels.numpy())\n",
    "    preds = model.predict(batch_images)\n",
    "    y_prob_list.append(preds)\n",
    "\n",
    "if len(y_true_list) == 0:\n",
    "    print('Validation set appears empty — cannot evaluate. Exiting.')\n",
    "    sys.exit(1)\n",
    "\n",
    "y_true = np.vstack(y_true_list)\n",
    "y_prob = np.vstack(y_prob_list)\n",
    "\n",
    "y_true_indices = np.argmax(y_true, axis=1)\n",
    "y_pred_indices = np.argmax(y_prob, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "\n",
    "# Create the normal confusion matrix\n",
    "create_normal_confusion_matrix(cm, class_names, 'confusion_matrix.png')\n",
    "\n",
    "# Also save the raw data\n",
    "np.save('confusion_matrix.npy', cm)\n",
    "try:\n",
    "    with open('confusion_matrix.json', 'w') as f:\n",
    "        json.dump(cm.tolist(), f)\n",
    "    print('Saved confusion matrix data to confusion_matrix.npy and confusion_matrix.json')\n",
    "except Exception as e:\n",
    "    print('Could not save confusion matrix JSON:', e)\n",
    "\n",
    "report = classification_report(y_true_indices, y_pred_indices, target_names=class_names, digits=4)\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print('Saved classification report to classification_report.txt')\n",
    "print('\\n' + report)\n",
    "\n",
    "# ROC curves\n",
    "if NUM_CLASSES == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_true[:, 1], y_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if PLOTTING_AVAILABLE:\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC - Binary')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig('roc_curve.png')\n",
    "        plt.close()\n",
    "        print('Saved ROC curve to roc_curve.png')\n",
    "    else:\n",
    "        try:\n",
    "            with open('roc_binary.json', 'w') as f:\n",
    "                json.dump({'fpr': fpr.tolist(), 'tpr': tpr.tolist(), 'auc': float(roc_auc)}, f)\n",
    "            print('Saved ROC data to roc_binary.json')\n",
    "        except Exception as e:\n",
    "            print('Could not save ROC JSON:', e)\n",
    "else:\n",
    "    fpr = dict(); tpr = dict(); roc_auc = dict()\n",
    "    for i in range(NUM_CLASSES):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr['micro'], tpr['micro'], _ = roc_curve(y_true.ravel(), y_prob.ravel())\n",
    "    roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "\n",
    "    if PLOTTING_AVAILABLE:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr['micro'], tpr['micro'], label=f'micro-average ROC (area = {roc_auc[\"micro\"]:.2f})', lw=2)\n",
    "        for i in range(NUM_CLASSES):\n",
    "            plt.plot(fpr[i], tpr[i], lw=1, label=f'ROC {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Multi-class ROC')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig('roc_curve_multiclass.png')\n",
    "        plt.close()\n",
    "        print('Saved multi-class ROC curve to roc_curve_multiclass.png')\n",
    "    else:\n",
    "        try:\n",
    "            roc_out = {}\n",
    "            for i in range(NUM_CLASSES):\n",
    "                roc_out[class_names[i]] = {'fpr': fpr[i].tolist(), 'tpr': tpr[i].tolist(), 'auc': float(roc_auc[i])}\n",
    "            roc_out['micro'] = {'fpr': fpr['micro'].tolist(), 'tpr': tpr['micro'].tolist(), 'auc': float(roc_auc['micro'])}\n",
    "            with open('roc_multiclass.json', 'w') as f:\n",
    "                json.dump(roc_out, f)\n",
    "            print('Saved ROC data to roc_multiclass.json')\n",
    "        except Exception as e:\n",
    "            print('Could not save ROC JSON:', e)\n",
    "\n",
    "print('All evaluation artifacts saved: metrics (JSON or PNGs), confusion matrix, ROC curve(s), classification report.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c37096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "CPU-only version of:\n",
    "Quantum Transfer Learning using InceptionV3 (feature extractor) + optional PennyLane quantum layer.\n",
    "\n",
    "This script forces TensorFlow to use CPU only (no GPUs), disables mixed precision, and preserves\n",
    "the remainder of your pipeline (dataset loading, MixUp, model, optional hyperparameter search, eval).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import json\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "# -------------------- FORCE CPU --------------------\n",
    "# Must set before importing tensorflow to ensure no GPU devices are used.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   # Force TF to ignore GPUs\n",
    "# Optionally set TF_CPP_MIN_LOG_LEVEL to reduce TF logging (0 = all, 1 = filter INFO, 2 = WARN, 3 = ERROR)\n",
    "# os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "# --------------------------------------------------\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Extra safety: if GPUs are still visible, hide them explicitly (no-op on CPU-only)\n",
    "try:\n",
    "    physical_gpus = tf.config.list_physical_devices('GPU')\n",
    "    if physical_gpus:\n",
    "        try:\n",
    "            tf.config.set_visible_devices([], 'GPU')\n",
    "        except Exception:\n",
    "            # Some TF versions may raise; continue anyway\n",
    "            pass\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Optional packages\n",
    "try:\n",
    "    import optuna\n",
    "    OPTUNA_AVAILABLE = True\n",
    "except Exception:\n",
    "    OPTUNA_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import keras_tuner as kt\n",
    "    KERASTUNER_AVAILABLE = True\n",
    "except Exception:\n",
    "    KERASTUNER_AVAILABLE = False\n",
    "\n",
    "# PennyLane for quantum layers (optional)\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    PENNYLANE_AVAILABLE = True\n",
    "except Exception:\n",
    "    PENNYLANE_AVAILABLE = False\n",
    "\n",
    "# matplotlib is optional. If missing, we'll fall back to saving numeric output.\n",
    "try:\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    PLOTTING_AVAILABLE = True\n",
    "except Exception:\n",
    "    PLOTTING_AVAILABLE = False\n",
    "    plt = None\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "\n",
    "# --------------------------- User settings ---------------------------\n",
    "DATA_DIR = \"im1\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "IMG_SIZE = (299, 299)\n",
    "BATCH_SIZE = 32  # CPU-friendly default\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "SEED = 123\n",
    "NUM_EPOCHS = 30\n",
    "INITIAL_EPOCHS = 30              # frozen-backbone training only\n",
    "FINE_TUNE_EPOCHS = 0             # disable fine-tuning\n",
    "FINE_TUNE_AT = 50                 # layers from the end of base_model to unfreeze\n",
    "DEFAULT_N_QUBITS = 4\n",
    "DEFAULT_Q_LAYERS = 2\n",
    "USE_QUANTUM = False               # keep False by default; enable only for experiments\n",
    "CACHE_DATASETS = True\n",
    "MIXUP_ALPHA = 0.15                # MixUp intensity (0 disables MixUp)\n",
    "LABEL_SMOOTHING = 0.08            # label smoothing for categorical crossentropy\n",
    "WEIGHT_DECAY = 1e-4               # AdamW weight decay\n",
    "DENSE_AFTER_Q = 512               # larger head\n",
    "DROPOUT_RATE = 0.5                # stronger dropout\n",
    "EARLYSTOP_PATIENCE = 10\n",
    "EXIT_AFTER_TRAIN = False         # run evaluation to generate confusion matrix\n",
    "THRESHOLD_ACC = 0.85             # stop early when val_accuracy reaches this\n",
    "\n",
    "# Hyperparameter search settings\n",
    "RUN_HP_SEARCH = False\n",
    "HP_TRIALS = 12\n",
    "HP_EPOCHS = 6\n",
    "HP_USE_OPTUNA = True\n",
    "\n",
    "# --------------------------- CPU / Strategy info ---------------------------\n",
    "# Use default strategy on CPU. We still call get_strategy() for compatibility.\n",
    "strategy = tf.distribute.get_strategy()\n",
    "print(\"Forcing CPU-only mode. TensorFlow devices visible:\", tf.config.get_visible_devices())\n",
    "print(f\"Using batch size = {BATCH_SIZE}\")\n",
    "# Note: mixed precision is intentionally NOT enabled for CPU training.\n",
    "\n",
    "# --------------------------- Utilities ---------------------------\n",
    "\n",
    "def compute_class_counts(train_dir):\n",
    "    classes = []\n",
    "    counts = {}\n",
    "    total = 0\n",
    "    if not os.path.isdir(train_dir):\n",
    "        return classes, counts, total\n",
    "    for d in sorted(os.listdir(train_dir)):\n",
    "        cls_path = os.path.join(train_dir, d)\n",
    "        if os.path.isdir(cls_path):\n",
    "            cnt = len([f for f in os.listdir(cls_path) if os.path.isfile(os.path.join(cls_path, f))])\n",
    "            classes.append(d)\n",
    "            counts[d] = cnt\n",
    "            total += cnt\n",
    "    return classes, counts, total\n",
    "\n",
    "\n",
    "def compute_class_weight_from_counts(counts):\n",
    "    classes = sorted(counts.keys())\n",
    "    total = sum(counts.values())\n",
    "    num_classes = len(classes) if len(classes) > 0 else 1\n",
    "    class_weight = {}\n",
    "    for i, cls in enumerate(classes):\n",
    "        cls_count = counts[cls]\n",
    "        if cls_count == 0:\n",
    "            class_weight[i] = 1.0\n",
    "        else:\n",
    "            class_weight[i] = total / (num_classes * cls_count)\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "# TF-native MixUp (batch-wise)\n",
    "@tf.function\n",
    "def mixup_batch(images, labels, alpha=MIXUP_ALPHA):\n",
    "    if alpha <= 0.0:\n",
    "        return images, labels\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    lam = tf.random.uniform([], 0.0, 1.0)\n",
    "    lam = tf.maximum(lam, 1.0 - lam)\n",
    "    lam = tf.cast(lam, images.dtype)\n",
    "    idx = tf.random.shuffle(tf.range(batch_size))\n",
    "    mixed_images = lam * images + (1.0 - lam) * tf.gather(images, idx)\n",
    "    mixed_labels = lam * labels + (1.0 - lam) * tf.gather(labels, idx)\n",
    "    return mixed_images, mixed_labels\n",
    "\n",
    "\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def loss(y_true, y_pred):\n",
    "        eps = 1e-7\n",
    "        y_pred = tf.clip_by_value(y_pred, eps, 1. - eps)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * tf.pow(1 - y_pred, gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_sum(loss, axis=1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Learning rate schedule: linear warmup + cosine decay\n",
    "class WarmUpCosine(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, base_lr: float, total_steps: int, warmup_steps: int = 0, min_lr: float = 0.0, name: str = None):\n",
    "        super().__init__()\n",
    "        self.base_lr = float(base_lr)\n",
    "        self.total_steps = int(max(1, total_steps))\n",
    "        self.warmup_steps = int(max(0, warmup_steps))\n",
    "        self.min_lr = float(min_lr)\n",
    "        self.name = name or \"WarmUpCosine\"\n",
    "\n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, tf.float32)\n",
    "        total = tf.cast(self.total_steps, tf.float32)\n",
    "        warm = tf.cast(self.warmup_steps, tf.float32)\n",
    "        base = tf.constant(self.base_lr, tf.float32)\n",
    "        min_lr = tf.constant(self.min_lr, tf.float32)\n",
    "\n",
    "        def lr_warmup():\n",
    "            # Linear warmup from min_lr to base over warmup steps\n",
    "            slope = (base - min_lr) / tf.maximum(1.0, warm)\n",
    "            return min_lr + slope * step\n",
    "\n",
    "        def lr_cosine():\n",
    "            # Cosine decay from base to min_lr over (total - warmup) steps\n",
    "            progress = (step - warm) / tf.maximum(1.0, (total - warm))\n",
    "            cosine_decay = 0.5 * (1.0 + tf.cos(tf.constant(math.pi) * tf.clip_by_value(progress, 0.0, 1.0)))\n",
    "            return min_lr + (base - min_lr) * cosine_decay\n",
    "\n",
    "        return tf.cond(step < warm, lr_warmup, lr_cosine)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"base_lr\": self.base_lr,\n",
    "            \"total_steps\": self.total_steps,\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "            \"min_lr\": self.min_lr,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "\n",
    "\n",
    "# Callback: stop when a metric crosses a threshold\n",
    "class StopOnMetricThreshold(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor: str = 'val_accuracy', threshold: float = 0.85):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.threshold = float(threshold)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        value = logs.get(self.monitor)\n",
    "        if value is not None and value >= self.threshold:\n",
    "            print(f\"Threshold reached: {self.monitor}={value:.4f} >= {self.threshold:.4f}. Stopping training.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# --------------------------- Load datasets ---------------------------\n",
    "print(f\"Loading training data from: {TRAIN_DIR}\")\n",
    "print(f\"Loading validation data from: {VAL_DIR}\")\n",
    "\n",
    "if not os.path.isdir(TRAIN_DIR) or not os.path.isdir(VAL_DIR):\n",
    "    print('Error: Train or Val directory not found. Please ensure the `im1/train` and `im1/val` directories exist and contain class subfolders.')\n",
    "    sys.exit(1)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    VAL_DIR,\n",
    "    seed=SEED,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(\"Detected classes:\", class_names)\n",
    "\n",
    "# compute counts & class weights\n",
    "classes_from_fs, counts, total = compute_class_counts(TRAIN_DIR)\n",
    "print('Training image counts per class (filesystem):', counts)\n",
    "class_weight = compute_class_weight_from_counts(counts)\n",
    "print('Computed class weights:', class_weight)\n",
    "\n",
    "imbalance_ratio = 1.0\n",
    "if counts:\n",
    "    min_count = min([v for v in counts.values() if v > 0])\n",
    "    if min_count > 0:\n",
    "        imbalance_ratio = max(counts.values()) / min_count\n",
    "use_focal = imbalance_ratio > 2.0\n",
    "if use_focal:\n",
    "    print(f\"Detected strong class imbalance (ratio={imbalance_ratio:.2f}) — using focal loss\")\n",
    "\n",
    "# Cache + prefetch\n",
    "if CACHE_DATASETS:\n",
    "    try:\n",
    "        train_ds = train_ds.cache()\n",
    "        val_ds = val_ds.cache()\n",
    "        print('Datasets cached in memory (if there is available RAM)')\n",
    "    except Exception as e:\n",
    "        print('Could not cache datasets:', e)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y), num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.map(lambda x, y: (tf.image.resize(x, IMG_SIZE), y), num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "if MIXUP_ALPHA > 0.0:\n",
    "    try:\n",
    "        train_ds = train_ds.map(lambda x, y: mixup_batch(x, y, MIXUP_ALPHA), num_parallel_calls=AUTOTUNE)\n",
    "        print('Applied MixUp augmentation to training dataset (TF-native)')\n",
    "    except Exception as e:\n",
    "        print('Could not apply MixUp via TF map — continuing without MixUp:', e)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.12),\n",
    "    layers.RandomZoom(0.12),\n",
    "    layers.RandomContrast(0.12),\n",
    "])\n",
    "\n",
    "# --------------------------- Quantum components (optional) ---------------------------\n",
    "if USE_QUANTUM and not PENNYLANE_AVAILABLE:\n",
    "    print(\"PennyLane not installed — quantum layer will be disabled automatically.\")\n",
    "    USE_QUANTUM = False\n",
    "\n",
    "# --------------------------- Model builder ---------------------------\n",
    "\n",
    "def build_feature_extractor():\n",
    "    base_model = tf.keras.applications.InceptionV3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "        pooling='avg'\n",
    "    )\n",
    "    return base_model\n",
    "\n",
    "\n",
    "def build_model(base_model, n_qubits=DEFAULT_N_QUBITS, q_layers=DEFAULT_Q_LAYERS, lr=1e-4, dense_after_q=DENSE_AFTER_Q, use_quantum=USE_QUANTUM, dropout_rate=DROPOUT_RATE, label_smoothing=LABEL_SMOOTHING, use_focal_loss=False):\n",
    "    base_model.trainable = False\n",
    "    inputs = tf.keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = tf.keras.applications.inception_v3.preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    if use_quantum and PENNYLANE_AVAILABLE:\n",
    "        x = layers.Dense(n_qubits, activation='tanh', name='proj_to_qubits')(x)\n",
    "        # quantum head omitted here for clarity\n",
    "        x = layers.Dense(dense_after_q, activation='relu')(x)\n",
    "    else:\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = layers.Dense(dense_after_q, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax', dtype='float32', name='predictions')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    def make_optimizer(opt_name, lr, weight_decay=WEIGHT_DECAY):\n",
    "        try:\n",
    "            if opt_name == 'adamw':\n",
    "                Opt = tf.keras.optimizers.experimental.AdamW\n",
    "                return Opt(learning_rate=lr, weight_decay=weight_decay)\n",
    "            elif opt_name == 'adam':\n",
    "                return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "            elif opt_name == 'sgd':\n",
    "                return tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "            else:\n",
    "                return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        except Exception:\n",
    "            return tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    optimizer = make_optimizer('adamw', lr)\n",
    "\n",
    "    if use_focal_loss:\n",
    "        loss_fn = categorical_focal_loss()\n",
    "    else:\n",
    "        loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --------------------------- Hyperparameter search (optional) ---------------------------\n",
    "# (unchanged; will run on CPU if enabled)\n",
    "\n",
    "def run_optuna_search(train_ds, val_ds, base_model, class_weight, trials=12, epochs_per_trial=6):\n",
    "    if not OPTUNA_AVAILABLE:\n",
    "        print('Optuna not available — skipping Optuna search')\n",
    "        return None\n",
    "\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            opt_name = trial.suggest_categorical('optimizer', ['adamw', 'adam', 'sgd'])\n",
    "            lr = trial.suggest_loguniform('lr', 1e-6, 1e-3)\n",
    "            weight_decay = trial.suggest_loguniform('weight_decay', 1e-7, 1e-3)\n",
    "            dropout = trial.suggest_float('dropout', 0.2, 0.6)\n",
    "            dense_head = trial.suggest_categorical('dense_head', [256, 512, 768])\n",
    "            mixup_alpha = trial.suggest_float('mixup_alpha', 0.0, 0.25)\n",
    "            label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.12)\n",
    "            fine_tune_at = trial.suggest_int('fine_tune_at', 20, 80)\n",
    "            use_focal = trial.suggest_categorical('use_focal', [False, True])\n",
    "\n",
    "            with strategy.scope():\n",
    "                model = build_model(base_model, lr=lr, dense_after_q=dense_head, dropout_rate=dropout, label_smoothing=label_smoothing, use_focal_loss=use_focal)\n",
    "\n",
    "            cb = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "\n",
    "            ds_train_for_trial = train_ds\n",
    "            if mixup_alpha > 0:\n",
    "                try:\n",
    "                    ds_train_for_trial = ds_train_for_trial.map(lambda x, y: mixup_batch(x, y, mixup_alpha), num_parallel_calls=AUTOTUNE)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            history = model.fit(ds_train_for_trial, validation_data=val_ds, epochs=epochs_per_trial, callbacks=cb, class_weight=class_weight, verbose=0)\n",
    "            val_acc = history.history.get('val_accuracy', [0])[-1]\n",
    "            tf.keras.backend.clear_session()\n",
    "            return val_acc\n",
    "        except Exception as e:\n",
    "            print('Trial failed with exception:', e)\n",
    "            traceback.print_exc()\n",
    "            tf.keras.backend.clear_session()\n",
    "            return 0.0\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "    print('Optuna study best params:', study.best_params)\n",
    "    return study.best_params\n",
    "\n",
    "\n",
    "def run_keras_tuner_search(train_ds, val_ds, base_model, class_weight, max_trials=8, epochs_per_trial=6):\n",
    "    if not KERASTUNER_AVAILABLE:\n",
    "        print('Keras Tuner not available — skipping tuner search')\n",
    "        return None\n",
    "\n",
    "    def model_builder(hp):\n",
    "        lr = hp.Float('lr', 1e-6, 1e-3, sampling='log', default=1e-4)\n",
    "        dropout = hp.Float('dropout', 0.2, 0.6, step=0.1, default=0.4)\n",
    "        dense_head = hp.Choice('dense_head', [256, 512, 768], default=512)\n",
    "        use_focal = hp.Boolean('use_focal', default=False)\n",
    "        model = build_model(base_model, lr=lr, dense_after_q=dense_head, dropout_rate=dropout, use_focal_loss=use_focal)\n",
    "        return model\n",
    "\n",
    "    tuner = kt.BayesianOptimization(model_builder, objective='val_accuracy', max_trials=max_trials, directory='kt_dir', project_name='quantum_inception_opt')\n",
    "    tuner.search(train_ds, validation_data=val_ds, epochs=epochs_per_trial, callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)], class_weight=class_weight)\n",
    "    best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    print('Keras Tuner best hyperparameters:', best_hp.values)\n",
    "    return best_hp.values\n",
    "\n",
    "# --------------------------- Build, train, fine-tune (main) ---------------------------\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model = build_feature_extractor()\n",
    "\n",
    "best_hp = None\n",
    "if RUN_HP_SEARCH:\n",
    "    print('Starting hyperparameter search...')\n",
    "    if OPTUNA_AVAILABLE and HP_USE_OPTUNA:\n",
    "        try:\n",
    "            best_hp = run_optuna_search(train_ds, val_ds, base_model, class_weight, trials=HP_TRIALS, epochs_per_trial=HP_EPOCHS)\n",
    "        except Exception as e:\n",
    "            print('Optuna search failed:', e)\n",
    "            best_hp = None\n",
    "    if best_hp is None and KERASTUNER_AVAILABLE:\n",
    "        try:\n",
    "            best_hp = run_keras_tuner_search(train_ds, val_ds, base_model, class_weight, max_trials=HP_TRIALS, epochs_per_trial=HP_EPOCHS)\n",
    "        except Exception as e:\n",
    "            print('Keras Tuner search failed:', e)\n",
    "            best_hp = None\n",
    "    print('Hyperparameter search complete. best_hp =', best_hp)\n",
    "\n",
    "if isinstance(best_hp, dict):\n",
    "    chosen_lr = best_hp.get('lr', 1e-4)\n",
    "    chosen_dropout = best_hp.get('dropout', DROPOUT_RATE)\n",
    "    chosen_dense = best_hp.get('dense_head', DENSE_AFTER_Q)\n",
    "    chosen_use_focal = best_hp.get('use_focal', use_focal)\n",
    "    chosen_weight_decay = best_hp.get('weight_decay', WEIGHT_DECAY)\n",
    "    chosen_fine_tune_at = best_hp.get('fine_tune_at', FINE_TUNE_AT)\n",
    "else:\n",
    "    chosen_lr = 1e-4\n",
    "    chosen_dropout = DROPOUT_RATE\n",
    "    chosen_dense = DENSE_AFTER_Q\n",
    "    chosen_use_focal = use_focal\n",
    "    chosen_weight_decay = WEIGHT_DECAY\n",
    "    chosen_fine_tune_at = FINE_TUNE_AT\n",
    "\n",
    "print('Final hyperparameters to use:')\n",
    "print(' lr=', chosen_lr, ' dropout=', chosen_dropout, ' dense=', chosen_dense, ' use_focal=', chosen_use_focal, ' weight_decay=', chosen_weight_decay, ' fine_tune_at=', chosen_fine_tune_at)\n",
    "\n",
    "with strategy.scope():\n",
    "    model = build_model(base_model, lr=chosen_lr, dense_after_q=chosen_dense, dropout_rate=chosen_dropout, label_smoothing=LABEL_SMOOTHING, use_focal_loss=chosen_use_focal)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_filepath = 'best_quantum_inception_cpu.h5'\n",
    "callbacks_initial = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    StopOnMetricThreshold(monitor='val_accuracy', threshold=THRESHOLD_ACC),\n",
    "]\n",
    "\n",
    "steps_per_epoch = math.ceil(total / BATCH_SIZE) if total > 0 else None\n",
    "\n",
    "# Re-compile model with warmup+cosine schedule for initial training when step info is available\n",
    "with strategy.scope():\n",
    "    if steps_per_epoch:\n",
    "        init_total_steps = INITIAL_EPOCHS * steps_per_epoch\n",
    "        init_warmup_steps = max(1, int(0.1 * init_total_steps))\n",
    "        init_lr_schedule = WarmUpCosine(\n",
    "            base_lr=chosen_lr,\n",
    "            total_steps=init_total_steps,\n",
    "            warmup_steps=init_warmup_steps,\n",
    "            min_lr=max(1e-7, chosen_lr * 0.1),\n",
    "        )\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            init_optimizer = Opt(learning_rate=init_lr_schedule, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            init_optimizer = tf.keras.optimizers.Adam(learning_rate=init_lr_schedule)\n",
    "    else:\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            init_optimizer = Opt(learning_rate=chosen_lr, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            init_optimizer = tf.keras.optimizers.Adam(learning_rate=chosen_lr)\n",
    "    model.compile(optimizer=init_optimizer, loss=model.loss, metrics=['accuracy'])\n",
    "\n",
    "# Choose callbacks for initial training depending on whether a schedule is used\n",
    "if steps_per_epoch:\n",
    "    callbacks_init_actual = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLYSTOP_PATIENCE, restore_best_weights=True),\n",
    "        StopOnMetricThreshold(monitor='val_accuracy', threshold=THRESHOLD_ACC),\n",
    "    ]\n",
    "else:\n",
    "    callbacks_init_actual = callbacks_initial\n",
    "\n",
    "print(\"\\n--- Starting initial training (frozen backbone) ---\\n\")\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    callbacks=callbacks_init_actual,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "# Fine-tune: unfreeze last chosen_fine_tune_at layers of base_model\n",
    "print(\"\\n--- Fine-tuning: unfreezing top layers of the base model ---\\n\")\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-chosen_fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-chosen_fine_tune_at:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "fine_tune_epochs = FINE_TUNE_EPOCHS\n",
    "if steps_per_epoch is None:\n",
    "    decay_steps = None\n",
    "else:\n",
    "    decay_steps = fine_tune_epochs * steps_per_epoch\n",
    "\n",
    "with strategy.scope():\n",
    "    ft_lr = chosen_lr * 0.05\n",
    "    if decay_steps:\n",
    "        # Use the same WarmUpCosine with short warmup for fine-tuning\n",
    "        ft_warmup_steps = max(1, int(0.1 * decay_steps))\n",
    "        lr_schedule = WarmUpCosine(\n",
    "            base_lr=ft_lr,\n",
    "            total_steps=decay_steps,\n",
    "            warmup_steps=ft_warmup_steps,\n",
    "            min_lr=max(1e-7, ft_lr * 0.2),\n",
    "        )\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            optimizer = Opt(learning_rate=lr_schedule, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    else:\n",
    "        try:\n",
    "            Opt = tf.keras.optimizers.experimental.AdamW\n",
    "            optimizer = Opt(learning_rate=ft_lr, weight_decay=chosen_weight_decay)\n",
    "        except Exception:\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=ft_lr)\n",
    "    model.compile(optimizer=optimizer, loss=model.loss, metrics=['accuracy'])\n",
    "\n",
    "# Choose callbacks for fine-tuning depending on whether a schedule is used\n",
    "if fine_tune_epochs > 0:\n",
    "    if decay_steps:\n",
    "        callbacks_ft = [\n",
    "            tf.keras.callbacks.ModelCheckpoint(checkpoint_filepath, monitor='val_accuracy', save_best_only=True),\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=EARLYSTOP_PATIENCE, restore_best_weights=True)\n",
    "        ]\n",
    "    else:\n",
    "        callbacks_ft = callbacks_initial\n",
    "\n",
    "    history2 = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=fine_tune_epochs,\n",
    "        callbacks=callbacks_ft,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "else:\n",
    "    history2 = None\n",
    "\n",
    "# Save final model\n",
    "model.save('quantum_inception_trained_finetuned_cpu.h5')\n",
    "print('Saved trained & fine-tuned model to quantum_inception_trained_finetuned_cpu.h5')\n",
    "\n",
    "if EXIT_AFTER_TRAIN:\n",
    "    sys.exit(0)\n",
    "\n",
    "# --------------------------- Consolidate history ---------------------------\n",
    "\n",
    "def merge_history(h1, h2):\n",
    "    if h2 is None:\n",
    "        return h1\n",
    "    merged = {}\n",
    "    for k in h1.history.keys():\n",
    "        merged[k] = h1.history[k] + h2.history.get(k, [])\n",
    "    return type('H', (), {'history': merged})\n",
    "\n",
    "history = merge_history(history1, history2)\n",
    "\n",
    "# --------------------------- Plot training curves ---------------------------\n",
    "\n",
    "def save_metrics_json(history, out_prefix='train'):\n",
    "    metrics = history.history\n",
    "    out_file = f\"{out_prefix}_metrics.json\"\n",
    "    try:\n",
    "        with open(out_file, 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        print(f\"Saved numeric training metrics to {out_file}\")\n",
    "    except Exception as e:\n",
    "        print('Could not save JSON metrics:', e)\n",
    "\n",
    "\n",
    "def plot_training(history, out_prefix='train'):\n",
    "    if not PLOTTING_AVAILABLE:\n",
    "        print('matplotlib not available — saving numeric metrics instead of plots')\n",
    "        save_metrics_json(history, out_prefix=out_prefix)\n",
    "        return\n",
    "\n",
    "    acc = history.history.get('accuracy', [])\n",
    "    val_acc = history.history.get('val_accuracy', [])\n",
    "    loss = history.history.get('loss', [])\n",
    "    val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "    epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    acc_png = f\"{out_prefix}_accuracy.png\"\n",
    "    plt.savefig(acc_png)\n",
    "    print(f\"Saved accuracy plot to {acc_png}\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    loss_png = f\"{out_prefix}_loss.png\"\n",
    "    plt.savefig(loss_png)\n",
    "    print(f\"Saved loss plot to {loss_png}\")\n",
    "    plt.close()\n",
    "\n",
    "plot_training(history)\n",
    "\n",
    "# --------------------------- Evaluation ---------------------------\n",
    "\n",
    "def create_normal_confusion_matrix(cm, class_names, save_path='confusion_matrix.png'):\n",
    "    \"\"\"\n",
    "    Create a normal, clean confusion matrix with standard matplotlib styling\n",
    "    \"\"\"\n",
    "    if not PLOTTING_AVAILABLE:\n",
    "        return\n",
    "    \n",
    "    # Create figure with standard size\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Use standard colormap (Blues)\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap='Blues', aspect='auto')\n",
    "    \n",
    "    # Add simple title\n",
    "    ax.set_title('Confusion Matrix - Diabetic Retinopathy Classification', \n",
    "                 fontsize=14, fontweight='normal', pad=20)\n",
    "    \n",
    "    # Add standard colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Number of Predictions', fontsize=10)\n",
    "    \n",
    "    # Set tick marks\n",
    "    tick_marks = np.arange(NUM_CLASSES)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right', fontsize=10)\n",
    "    ax.set_yticklabels(class_names, fontsize=10)\n",
    "    \n",
    "    # Add simple grid\n",
    "    ax.grid(False)\n",
    "    \n",
    "    # Add text annotations with simple styling\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        value = cm[i, j]\n",
    "        \n",
    "        # Simple text color based on cell value\n",
    "        if value > thresh:\n",
    "            text_color = \"white\"\n",
    "        else:\n",
    "            text_color = \"black\"\n",
    "        \n",
    "        # Add the count with simple styling\n",
    "        ax.text(j, i, f'{value:d}',\n",
    "                horizontalalignment=\"center\",\n",
    "                verticalalignment=\"center\",\n",
    "                color=text_color,\n",
    "                fontsize=10)\n",
    "    \n",
    "    # Standard axis labels\n",
    "    ax.set_ylabel('True Label', fontsize=12)\n",
    "    ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "    \n",
    "    # Standard background\n",
    "    ax.set_facecolor('white')\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    # Standard spines\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save with standard quality\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved normal confusion matrix to {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "# --------------------------- Evaluation ---------------------------\n",
    "\n",
    "y_true_list = []\n",
    "y_prob_list = []\n",
    "\n",
    "for batch_images, batch_labels in val_ds:\n",
    "    y_true_list.append(batch_labels.numpy())\n",
    "    preds = model.predict(batch_images)\n",
    "    y_prob_list.append(preds)\n",
    "\n",
    "if len(y_true_list) == 0:\n",
    "    print('Validation set appears empty — cannot evaluate. Exiting.')\n",
    "    sys.exit(1)\n",
    "\n",
    "y_true = np.vstack(y_true_list)\n",
    "y_prob = np.vstack(y_prob_list)\n",
    "\n",
    "y_true_indices = np.argmax(y_true, axis=1)\n",
    "y_pred_indices = np.argmax(y_prob, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "\n",
    "# Create the normal confusion matrix\n",
    "create_normal_confusion_matrix(cm, class_names, 'confusion_matrix.png')\n",
    "\n",
    "# Also save the raw data\n",
    "np.save('confusion_matrix.npy', cm)\n",
    "try:\n",
    "    with open('confusion_matrix.json', 'w') as f:\n",
    "        json.dump(cm.tolist(), f)\n",
    "    print('Saved confusion matrix data to confusion_matrix.npy and confusion_matrix.json')\n",
    "except Exception as e:\n",
    "    print('Could not save confusion matrix JSON:', e)\n",
    "\n",
    "report = classification_report(y_true_indices, y_pred_indices, target_names=class_names, digits=4)\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "print('Saved classification report to classification_report.txt')\n",
    "print('\\n' + report)\n",
    "\n",
    "# ROC curves\n",
    "if NUM_CLASSES == 2:\n",
    "    fpr, tpr, _ = roc_curve(y_true[:, 1], y_prob[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if PLOTTING_AVAILABLE:\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC - Binary')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig('roc_curve.png')\n",
    "        plt.close()\n",
    "        print('Saved ROC curve to roc_curve.png')\n",
    "    else:\n",
    "        try:\n",
    "            with open('roc_binary.json', 'w') as f:\n",
    "                json.dump({'fpr': fpr.tolist(), 'tpr': tpr.tolist(), 'auc': float(roc_auc)}, f)\n",
    "            print('Saved ROC data to roc_binary.json')\n",
    "        except Exception as e:\n",
    "            print('Could not save ROC JSON:', e)\n",
    "else:\n",
    "    fpr = dict(); tpr = dict(); roc_auc = dict()\n",
    "    for i in range(NUM_CLASSES):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_prob[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr['micro'], tpr['micro'], _ = roc_curve(y_true.ravel(), y_prob.ravel())\n",
    "    roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "\n",
    "    if PLOTTING_AVAILABLE:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr['micro'], tpr['micro'], label=f'micro-average ROC (area = {roc_auc[\"micro\"]:.2f})', lw=2)\n",
    "        for i in range(NUM_CLASSES):\n",
    "            plt.plot(fpr[i], tpr[i], lw=1, label=f'ROC {class_names[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Multi-class ROC')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig('roc_curve_multiclass.png')\n",
    "        plt.close()\n",
    "        print('Saved multi-class ROC curve to roc_curve_multiclass.png')\n",
    "    else:\n",
    "        try:\n",
    "            roc_out = {}\n",
    "            for i in range(NUM_CLASSES):\n",
    "                roc_out[class_names[i]] = {'fpr': fpr[i].tolist(), 'tpr': tpr[i].tolist(), 'auc': float(roc_auc[i])}\n",
    "            roc_out['micro'] = {'fpr': fpr['micro'].tolist(), 'tpr': tpr['micro'].tolist(), 'auc': float(roc_auc['micro'])}\n",
    "            with open('roc_multiclass.json', 'w') as f:\n",
    "                json.dump(roc_out, f)\n",
    "            print('Saved ROC data to roc_multiclass.json')\n",
    "        except Exception as e:\n",
    "            print('Could not save ROC JSON:', e)\n",
    "\n",
    "print('All evaluation artifacts saved: metrics (JSON or PNGs), confusion matrix, ROC curve(s), classification report.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
